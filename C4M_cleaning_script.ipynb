{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S4gIzcHv3bb_"
   },
   "source": [
    "# Coursera for Michigan - Data Cleaning Script\n",
    "*Date: June 18, 2020*\n",
    "\n",
    "The script is used to clean the data, and link student term, coursera enrollment, and term files together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8qkHlSz2MX3"
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "# Read in the files\n",
    "coursera_enrollment = pd.read_csv('coursera_enrollment_hashed.csv')\n",
    "student_term = pd.read_csv('student_term_with_descriptions_hashed.csv')\n",
    "term = pd.read_csv('term.csv')\n",
    "course = pd.read_csv('coursera_course.csv')\n",
    "spec = pd.read_csv('coursera_specialization.csv')\n",
    "specourse = pd.read_csv('coursera_specializationcourses.csv')\n",
    "\n",
    "\n",
    "# Clean up the student_term file: ----------------------------------------------\n",
    "# Filter student term file by registration_status and withdraw_code\n",
    "student_term_new = student_term[(student_term['registration_status'] == 'RGSD') & \n",
    "                                (student_term['withdraw_code'] == 'NWD')]\n",
    "\n",
    "# Filter the latest term\n",
    "idx = (student_term_new.groupby(['username'])['term_id'].\n",
    "       transform(max) == student_term_new['term_id'])\n",
    "student_term_new = student_term_new[idx]\n",
    "\n",
    "# Term file provides the descriptions of term_id, we add the term begin/end date to the student term file\n",
    "term_info = (term.loc[:,['code', 'begin_date', 'end_date']].\n",
    "             rename(columns={'code': 'term_id','begin_date': 'term_begin_date', \n",
    "                             'end_date': 'term_end_date'}))\n",
    "student_term_new = student_term_new.merge(term_info, on='term_id', how='left')\n",
    "student_term_new.head()\n",
    "\n",
    "# Clean up the coursera_enrollment file: ---------------------------------------\n",
    "# Keep only user_id before @umich\n",
    "coursera_enrollment['id'] = coursera_enrollment['id'].str.split('@').str[0]\n",
    "coursera_enrollment.rename(columns={'id': 'username'}, inplace=True)\n",
    "\n",
    "# Remove 'course~' in course_id column\n",
    "coursera_enrollment['course_id'] = coursera_enrollment['course_id'].str.split('~').str[1]\n",
    "# Remove 'specialization~' in specialization_id column\n",
    "coursera_enrollment['specialization_id'] = coursera_enrollment['specialization_id'].str.split('~').str[1]\n",
    "\n",
    "# Add two columns\n",
    "coursera_enrollment['is_alumnus'] = np.where(coursera_enrollment.program_id == '2ul8M6yGEeiHrwrBL_30oA', 1, 0)\n",
    "coursera_enrollment['is_complete'] = np.where(np.isnan(coursera_enrollment.grade), 0, 1)\n",
    "\n",
    "# Left join course info\n",
    "course_info = (course.loc[:, ['content_id', 'name']].\n",
    "               rename(columns={'content_id': 'course_id', 'name': 'course_name'}))\n",
    "coursera_enrollment = coursera_enrollment.merge(course_info, on='course_id', how='left')\n",
    "\n",
    "# Left join specialization info\n",
    "spec = pd.read_csv('coursera_specialization.csv')\n",
    "specourse = pd.read_csv('coursera_specializationcourses.csv')\n",
    "spec = (spec.loc[:, ['content_id', 'name']].\n",
    "        rename(columns = {'content_id': 'specialization_id', 'name': 'specialization_name'}))\n",
    "specourse = (specourse.loc[:, ['order', 'course_id', 'specialization_id']].\n",
    "             rename(columns = {'order': 'course_order'}))\n",
    "specourse['course_id'] = specourse['course_id'].str.split('~').str[1]\n",
    "specourse['specialization_id'] = specourse['specialization_id'].str.split('~').str[1]\n",
    "spec_info = specourse.merge(spec[['specialization_id', 'specialization_name']], on='specialization_id')\n",
    "\n",
    "coursera_enrollment_new = coursera_enrollment.merge(spec_info, on='course_id', how='left')\n",
    "\n",
    "x = (coursera_enrollment.\n",
    "     merge(spec_info[['specialization_id', 'specialization_name']], on='specialization_id', how='left').\n",
    "     drop_duplicates().specialization_name)\n",
    "\n",
    "coursera_enrollment_new['specialization_name'] = (\n",
    "    np.where(pd.isnull(coursera_enrollment_new['specialization_name']), \n",
    "             x, coursera_enrollment_new['specialization_name']))\n",
    "\n",
    "coursera_enrollment_new.drop('specialization_id_y', axis=1, inplace=True)\n",
    "coursera_enrollment_new.rename(columns={'specialization_id_x': 'specialization_id'}, inplace=True)\n",
    "\n",
    "# Inner join student term and Coursera enrollment files: -----------------------\n",
    "# Extract key columns\n",
    "enrol_info = ['username', 'enrolled_date', 'last_activity', 'overall_progress', \n",
    "              'grade', 'course_id', 'course_name','specialization_id', 'specialization_name',\n",
    "              'course_order', 'is_alumnus', 'is_complete']\n",
    "\n",
    "std_info = ['username', 'career_id', 'career_description', 'term_id', \n",
    "            'term_begin_date', 'term_end_date','program_description', \n",
    "            'primary_plan', 'plan_description', 'student_year']\n",
    "\n",
    "std_enrol = student_term_new[std_info].merge(coursera_enrollment_new[enrol_info], on='username')\n",
    "\n",
    "# Further std_enrol file cleanup\n",
    "# Format the date\n",
    "std_enrol['term_begin_date'] = pd.to_datetime(std_enrol['term_begin_date']).dt.date\n",
    "std_enrol['term_end_date'] = pd.to_datetime(std_enrol['term_end_date']).dt.date\n",
    "std_enrol['enrolled_date'] = pd.to_datetime(std_enrol['enrolled_date'], utc=True).dt.normalize().dt.date\n",
    "\n",
    "find_dup = std_enrol.groupby(['username'])['career_id'].nunique()\n",
    "idx = find_dup[find_dup == 2].index.tolist()\n",
    "\n",
    "size = 1       # sample size\n",
    "replace = True  # with replacement\n",
    "fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:].iloc[:,:2]\n",
    "np.random.seed(1)\n",
    "rdn_idx = std_enrol[std_enrol.username.isin(np.array(idx))].groupby(['username'], as_index=False).apply(fn)\n",
    "\n",
    "std_enrol = std_enrol[~(\n",
    "    (std_enrol['username'].isin(np.array(rdn_idx['username']))) & \n",
    "    (std_enrol['career_id'].isin(np.array(rdn_idx['career_id'])))\n",
    "    )]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Export the file and it's good to import into Tableau and run the views!\n",
    "# ------------------------------------------------------------------------------\n",
    "dte = dt.date.today().strftime('%m%d')\n",
    "file_name = \"student_enrollment_{}.csv\".format(dte)\n",
    "std_enrol.to_csv(file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "C4M cleaning script.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
